{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amelievert/JAD-Up/blob/main/Projet_JAD'Up.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsfm0KCuyPWW"
      },
      "source": [
        "# Projet d'application Streamlit"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.7.9 . So i Recommend to uninstall all the previous version and install python 3.7 and try running the command: \"pip install streamlit\" or \"pip install --upgrade streamlit\"\n",
        "\n"
      ],
      "metadata": {
        "id": "3q7p_a0j8Ond"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxZmRS0AyV5y"
      },
      "source": [
        "### Installation Streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZHGxkgYhcEZ"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbRTmXNhy8ae"
      },
      "source": [
        "### Configuration du site"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "decbyG24zBPo"
      },
      "outputs": [],
      "source": [
        "%%writefile streamlit_app.py \n",
        "\n",
        "# ______________________________________________________________________________________________________\n",
        "# Import des bibliothèques\n",
        "# ______________________________________________________________________________________________________\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier \n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "\n",
        "# ______________________________________________________________________________________________________\n",
        "# Configuration du site\n",
        "# ______________________________________________________________________________________________________\n",
        "\n",
        "st.set_page_config(page_title=\"JAD'Up\",  layout='wide', page_icon='/content/Agence de Marketing.ico')\n",
        "\n",
        "st.sidebar.title(\"Sommaire\")\n",
        "st.sidebar.image('/content/Agence de Marketing.ico')\n",
        "\n",
        "pages = [\"Introduction au jeu de données\",\n",
        "         \"Analyse\",\n",
        "         \"Preprocessing\",\n",
        "         \"Challenge de modèles\",\n",
        "         \"Pour aller plus loin\"]\n",
        "\n",
        "page = st.sidebar.radio(\"Aller vers\", pages) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r13z8KkwzUbW"
      },
      "source": [
        "### Préparation des jeux de données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpFAZyPSzKwx"
      },
      "outputs": [],
      "source": [
        "%%writefile streamlit_app.py \n",
        "\n",
        "# ______________________________________________________________________________________________________\n",
        "# Import du jeu de données\n",
        "# ______________________________________________________________________________________________________\n",
        "\n",
        "df = pd.read_csv('/content/bank.csv', sep = ',')\n",
        "\n",
        "\n",
        "# ______________________________________________________________________________________________________\n",
        "# Préparation des jeux de données à utiliser\n",
        "# ______________________________________________________________________________________________________\n",
        "\n",
        "df2 = df.copy()\n",
        "\n",
        "# Creation de tranches d'âges\n",
        "df2['t_age'] = pd.cut(x = df2['age'], bins = [17, 30, 40, 50, 65, 96], labels = ['18-30', '30-40','40-50', '50-65','65-95'])\n",
        "\n",
        "# Creation de tranches de solde compte bancaire = balance\n",
        "df2['t_balance'] = pd.qcut(x=df2[\"balance\"], q=4, labels=[1,2,3,4])\n",
        "\n",
        "# Creation de tranches de durée de contact = duration\n",
        "df2['t_duration'] = pd.qcut(df2[\"duration\"], q=4, labels=[1,2,3,4])\n",
        "\n",
        "# Creation de tranches de durée de contact = duration\n",
        "df2['t_duration'] = pd.qcut(df2[\"duration\"], q=4, labels=[1,2,3,4])\n",
        "\n",
        "# Creation de tranches de nombre de contact = campaign > Corrige le problème de valeurs abbérantes et limite à 4 contacts\n",
        "df2['t_campaign'] = pd.cut(x = df2['campaign'], bins = [0, 1, 2, 3, 99], labels = [1, 2, 3, 4])\n",
        "\n",
        "# Création d'une catégorie pour contact campagne précédente oui/non\n",
        "df2['contact_last_campaign'] = np.where(df2['pdays']>=0, 'yes', 'no')\n",
        "\n",
        "# Création de tranches en fonction du délai écoulé\n",
        "df2['t_pdays'] = pd.cut(x = df2['pdays'], bins = [-2, 0, 200, 999], labels = ['NON CONTACTE', 'MOINS DE 200J', 'PLUS DE 200J'])\n",
        "\n",
        "# Creation de tranches de nombre de contact avant la campagne\n",
        "df2['previous'] = pd.cut(x = df2['previous'], bins = [0, 1, 2, 3, 99], labels = [1, 2, 3, 4])\n",
        "\n",
        "# Suppression des colonnes dummies\"ées\"\n",
        "drop_cols=['age','balance','duration','campaign','pdays','previous']\n",
        "df2 = df2.drop(drop_cols, axis=1)\n",
        "\n",
        "# Création de dummies\n",
        "var=['marital','education','poutcome','contact','t_age','t_balance','t_duration','t_campaign','t_pdays','month']\n",
        "df2= df2.join(pd.get_dummies(df2[var], prefix=var))\n",
        "df2 = df2.drop(df2[var], axis=1)\n",
        "\n",
        "# Transformation en numérique\n",
        "le = LabelEncoder()\n",
        "df2['job2']= le.fit_transform(df2['job'])\n",
        "df2 = df2.drop(['job'], axis=1)\n",
        "\n",
        "# Remplace yes/no par 1/0\n",
        "var = [\"default\", \"housing\",\"loan\",\"deposit\",\"contact_last_campaign\"]\n",
        "df2[var] = df2[var].replace(('yes', 'no'), (1, 0))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cy6gdue80NEP"
      },
      "source": [
        "# Construction du site"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGTRoPZHzcDj"
      },
      "source": [
        "### Page 0 - Introduction au jeu de données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4qWjCJXzkMz"
      },
      "outputs": [],
      "source": [
        "%%writefile streamlit_app.py \n",
        "\n",
        "# ______________________________________________________________________________________________________\n",
        "# 1/ Introduction au jeu de données\n",
        "# ______________________________________________________________________________________________________\n",
        "\n",
        "if page==pages[0]: \n",
        "\n",
        "  st.title(\"Description du jeu de données\")\n",
        "\n",
        "  st.write(\"Ce jeu de données est composé de données personnelles sur des clients d’une banque qui ont été “télémarketés” pour souscrire à un produit que l’on appelle un 'dépôt à terme'.\")\n",
        "  st.write(\"Lorsqu’un client souscrit à ce produit, il place une quantité d’argent dans un compte spécifique et ne pourra pas toucher ces fonds avant l’expiration du terme.\")\n",
        "  st.write(\"En échange, le client reçoit des intérêts de la part de la banque à la fin du terme.\")\n",
        "  st.write(\"Le jeu de données est téléchargeable au lien suivant: \")\n",
        "  st.write(\"https://www.kaggle.com/janiobachmann/bank-marketing-dataset\")\n",
        "\n",
        "\n",
        "# ---------- Les chiffres clés -----------\n",
        "\n",
        "  st.header(\"Les chiffres clés :\")\n",
        "  col1, col2, col3, col4, col5 = st.columns(5)\n",
        "  col1.write('')\n",
        "  col2.metric(\"Nombre de clients\", \"11 162\")\n",
        "  col3.metric(\"Nombre de features\", \"17\")\n",
        "  col4.metric(\"Proportion des cibles\", \"47%\")\n",
        "  col5.write('')\n",
        "\n",
        "# ---------- les variables  -----------\n",
        "\n",
        "  st.header(\"Description des variables :\")\n",
        "\n",
        "  var = pd.DataFrame({\"Nom des variables\": [\"age\",\"job\",\"marital\",\"education\",\"default\",\"balance\",\"housing\",\"loan\",\"contact\",\"day\",\"month\",\"duration\",\"campaign\",\"pdays\",\"previous\",\"poutcome\",\"deposit\"],\n",
        "    \"Description\": [\"Age du client\",\"Profession\",\"Statut marital\",\"Niveau d'études\",\"Défaut de paiement\",\"Solde du compte\",\"Prêt immo\",\"Prêt perso\",\n",
        "    \"Type de contact\",\"Dernier jour de contact\",\"Dernier mois de  contact\",\"Durée du contact (secondes)\",\"Nombre de contacts\",\"Nb jours écoulés depuis le dernier contact\",\"Nb de contacts\",\n",
        "    \"Résultat de la campagne précédente\",\"Résultat de la campagne en cours\"]\n",
        "    })\n",
        "\n",
        "  st.write(var)\n",
        "\n",
        "# ---------- Aperçu -----------\n",
        "\n",
        "  st.header(\"Aperçu du jeu de données :\")\n",
        "  st.write(df)\n",
        "\n",
        "# ---------- Ce qu'il faut comprendre -----------\n",
        "\n",
        "  st.header(\"Ce qu'il faut retenir :\")\n",
        "  st.write(\"On remarque que certaines variables sont la résultante de la campagne en cours : \")\n",
        "  st.write(\"* contact\")\n",
        "  st.write(\"* day\")\n",
        "  st.write(\"* month\")\n",
        "  st.write(\"* duration\")\n",
        "  st.write(\"* campaign\")\n",
        "  st.write(\"La variable [deposit] est notre variable cible.\")\n",
        "  st.write(\"47% des clients ont répondu favorablement à la campagne (deposit=yes)\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA5wCQBgzue0"
      },
      "source": [
        "### Page 1 - Analyse du jeu de données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQ1lXYj-zw5Q"
      },
      "outputs": [],
      "source": [
        "%%writefile streamlit_app.py \n",
        "\n",
        "# ______________________________________________________________________________________________________\n",
        "# 2/ Analyse du jeu de données\n",
        "# ______________________________________________________________________________________________________\n",
        "\n",
        "if page==pages[1]: \n",
        "\n",
        "  st.title(\"Analyse du jeu de données\")\n",
        "\n",
        "# ---------- Fonction de description -----------\n",
        "\n",
        "  def describe_df(df):\n",
        "      \"\"\"\n",
        "      Fonction améliorée de description des colonnes, elle permet d'identifier :\n",
        "      le type de la colonne , le nb de valeur vide (nan), le nb de valeurs uniques, le pourcentage de répartition des valeurs\n",
        "      INPUT : le dataframe\n",
        "      OUTPUT : tableau d'analyse\n",
        "      \"\"\"\n",
        "      res = pd.DataFrame(index=[\"Name\",\"Type\", \"Nan\", \"Unique\",\"Min\",\"Max\",\"Values\",\"Pourcentage\"])\n",
        "      for col in df.columns:\n",
        "          df_col = df[col]\n",
        "          res[col] = [\n",
        "              df_col.name,\n",
        "              df_col.dtype,\n",
        "              df_col.isnull().sum(),\n",
        "              len(df_col.unique()),\n",
        "              df_col.min(),\n",
        "              df_col.max(),\n",
        "              df_col.unique(),\n",
        "              (df_col.value_counts(ascending=False, normalize=True) * 100)\n",
        "                  .apply(int)\n",
        "                  .to_json(),\n",
        "          ]\n",
        "      return res.T\n",
        "\n",
        "# ---------- Affichage de la description détaillée -----------\n",
        "\n",
        "  description = st.expander(\"Afficher la description des colonnes\")\n",
        "  description.dataframe(describe_df(df).astype(str))\n",
        "\n",
        "\n",
        "# ---------- Les correlations -----------\n",
        "\n",
        "  col1, col2 = st.columns(2)\n",
        "\n",
        "# Matrice de correlation\n",
        "\n",
        "  le = LabelEncoder()\n",
        "  df2=df.copy()\n",
        "  for col in df2.columns:\n",
        "    df2[col]= le.fit_transform(df2[col])\n",
        "  \n",
        "  col1.subheader(\"Matrice de corrélation\")\n",
        "\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  sns.heatmap(df2.corr(), annot=True, cmap='RdBu_r', center=0)\n",
        "  col1.pyplot(fig)\n",
        "\n",
        "\n",
        "# Corrélations directes\n",
        "\n",
        "  tab1, tab2 = col2.tabs([\"📈 Chart\", \"🗃 Coefficients\"])\n",
        "\n",
        "  tab1.subheader(\"Graphiques des corrélations directes\")\n",
        "  \n",
        "  corr=pd.DataFrame(df2.corr()[\"deposit\"])\n",
        "  corr=corr.sort_values(\"deposit\",ascending=False, key=abs)\n",
        "\n",
        "  fig = plt.figure(figsize=(10,7))\n",
        "  fig = px.bar(corr,\n",
        "                 x=\"Deposit\",\n",
        "                 y=corr.index,\n",
        "                 template = 'seaborn')\n",
        "  tab1.plotly_chart(fig, use_container_width=True) \n",
        "\n",
        "\n",
        "  tab2.subheader(\"Coefficients\")\n",
        "\n",
        "  coef=df2.corr()[\"deposit\"]\n",
        "  tab2.write(coef)\n",
        "\n",
        "# ---------- Les observations -----------\n",
        "\n",
        "  st.subheader(\"Observations :\")\n",
        "\n",
        "  st.write(\"Dans l'ordre, les variables les plus corrélées (valeur absolue) avec la target 'déposit' sont :\")\n",
        "  st.write(\"* duration*** = Durée du contact (en secondes)\")\n",
        "  st.write(\"* contact*** = Type de contact\")\n",
        "  st.write(\"* housing = Prêt immo\")\n",
        "  st.write(\"* previous = Nb contacts au cours de la campagne précédente\")\n",
        "  st.write(\"* pdays = Nb jours écoulés depuis le dernier contact de la campagne précédente\")\n",
        "  st.write(\"* balance = Solde compte bancaire\")\n",
        "  st.write(\"*** : attention , deux variables correspondent à des données non connues à priori (avant lancement de la campagne\")\n",
        "\n",
        "\n",
        "# ---------- Les distributions par type de variables -----------\n",
        "\n",
        "  st.subheader(\"Les distributions :\")\n",
        "  col3, col4 = st.columns(2)\n",
        "  df2 = df.copy()\n",
        "  numerics = df2.select_dtypes(include=['int16', 'int32', 'int64', 'float16', 'float32', 'float64']).columns\n",
        "  categoricals= df2.select_dtypes(include=['object','category']).columns\n",
        "\n",
        "\n",
        "# variables numériques\n",
        "\n",
        "  col3.subheader(\"Variables numériques\")\n",
        "  tab3, tab4 = col3.tabs([\"🗃 Describe\", \"📈 Chart\"])\n",
        "\n",
        "  describe= df2[numerics].describe().transpose()\n",
        "  tab3.write(describe)\n",
        "\n",
        "  option = tab4.selectbox(\"Choix une variable numérique :\",numerics)\n",
        "  hist = px.histogram(df2,x=option,color=\"deposit\",barmode=\"group\")\n",
        "  tab4.plotly_chart(hist)\n",
        "\n",
        "  if option==\"age\":\n",
        "    tab4.write(\"Les âges extrêmes semblent avoir une plus forte adhérence avec la campagne.\")\n",
        "  elif option==\"balance\":\n",
        "    tab4.write(\"RAS\")\n",
        "  elif option==\"day\":\n",
        "    tab4.write(\"RAS\")\n",
        "  elif option==\"duration\":\n",
        "    tab4.write(\"On remarque que plus la durée de contact augmente et plus les clients semblent souscrire à la campagne.\")\n",
        "  elif option==\"campaign\":\n",
        "    tab4.write(\"RAS\")\n",
        "  elif option==\"pdays\":\n",
        "    tab4.write(\"RAS\")\n",
        "  elif option==\"previous\":\n",
        "    tab4.write(\"RAS\")\n",
        "\n",
        "  col3.header(\"Observations\")\n",
        "  col3.write(\"On remarque que 8 324 clients n'ont pas été contactés lors de la campagne précédente.\")\n",
        "  col3.write(\"Lorsque PREVIOUS = 0 alors PDAYS = -1\")\n",
        "\n",
        "# variables catégorielles\n",
        "\n",
        "  col4.subheader(\"Variables catégorielles\")\n",
        "  tab5, tab6 = col3.tabs([\"🗃 Describe\", \"📈 Chart\"])\n",
        "\n",
        "  describe= df2[categoricals].describe().transpose()\n",
        "  tab5.write(describe)\n",
        "\n",
        "  option = tab6.selectbox(\"Choix une variable :\", categoricals)\n",
        "  hist = px.histogram(df2,x=option,color=\"deposit\")\n",
        "  tab6.plotly_chart(hist)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJf1c-eGz0yZ"
      },
      "source": [
        "### Page 2 - Préprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCc_xN5Dz2-S"
      },
      "outputs": [],
      "source": [
        "%%writefile streamlit_app.py \n",
        "\n",
        "# ______________________________________________________________________________________________________\n",
        "# 3/ Préprocessing\n",
        "# ______________________________________________________________________________________________________\n",
        "\n",
        "\n",
        "if page==pages[2]: \n",
        "\n",
        "  st.title(\"Préprocessing - Modèles prédictifs\")\n",
        "\n",
        "# ---------- Remise à situation d'origine -----------\n",
        "\n",
        "  # Réimport du fichier\n",
        "  df2 = df.copy()\n",
        "\n",
        "# ---------- Temps de preprocessing -----------\n",
        "\n",
        "  st.write(\"Attendre le traitement des variables ...\")\n",
        "\n",
        "  import time\n",
        "  my_bar = st.progress(0)\n",
        "  for percent_complete in range(100):\n",
        "      time.sleep(0.1)\n",
        "      my_bar.progress(percent_complete + 1)\n",
        "\n",
        "\n",
        "# ---------- Le préprocessing, ça sert à quoi -----------\n",
        "\n",
        "  expander1 = st.expander(\"Le préprocessing, ça sert à quoi ?\")\n",
        "  expander1.dataframe(describe_df(df).astype(str))\n",
        "\n",
        "  expander1.write(\"Le préprocessing est une de composante essentielle de la data science.\")\n",
        "  expander1.write(\"Cette étape décrit toutes les transformations effectuées sur le jeu de données initial et indispensables à la création du modèle d'apprentissage fiable et robuste.\")\n",
        "  expander1.write(\"Les algorithmes d'apprentissage automatique fonctionnent mieux lorsque les données sont présentées dans un format qui met en évidence les aspects pertinents requis pour résoudre un problème.\")\n",
        "  expander1.write(\"Les fonctions de préprocessing consistent à : \")\n",
        "  expander1.write(\"* la transformation des données,\")\n",
        "  expander1.write(\"* la réduction des données,\")\n",
        "  expander1.write(\"* la sélection des variables\")\n",
        "  expander1.write(\"* et à la mise à l'échelle\")\n",
        "  expander1.write(\"pour restructurer les données brutes sous une forme adaptée à des types particuliers d'algorithmes.\")\n",
        "\n",
        "  from PIL import Image\n",
        "  image = Image.open('preprocessing.JPG')\n",
        "  expander1.image(image, caption='Les étapes de préprocessing')\n",
        "\n",
        "# ---------- Les étapes de préprocessing -----------\n",
        "\n",
        "  st.header(\"Les étapes de préprocessing appliquées :\")\n",
        "\n",
        "  code = ''' \n",
        "    # Creation de tranches d'âges\n",
        "    df2['t_age'] = pd.cut(x = df2['age'], bins = [17, 30, 40, 50, 65, 96], labels = ['18-30', '30-40','40-50', '50-65','65-95'])\n",
        "\n",
        "    # Creation de tranches de solde compte bancaire = balance\n",
        "    df2['t_balance'] = pd.qcut(x=df2[\"balance\"], q=4, labels=[1,2,3,4])\n",
        "\n",
        "    # Creation de tranches de durée de contact = duration\n",
        "    df2['t_duration'] = pd.qcut(df2[\"duration\"], q=4, labels=[1,2,3,4])\n",
        "\n",
        "    # Creation de tranches de durée de contact = duration\n",
        "    df2['t_duration'] = pd.qcut(df2[\"duration\"], q=4, labels=[1,2,3,4])\n",
        "\n",
        "    # Creation de tranches de nombre de contact = campaign > Corrige le problème de valeurs abbérantes et limite à 4 contacts\n",
        "    df2['t_campaign'] = pd.cut(x = df2['campaign'], bins = [0, 1, 2, 3, 99], labels = [1, 2, 3, 4])\n",
        "\n",
        "    # Création d'une catégorie pour contact campagne précédente oui/non\n",
        "    df2['contact_last_campaign'] = np.where(df2['pdays']>=0, 'yes', 'no')\n",
        "\n",
        "    # Création de tranches en fonction du délai écoulé\n",
        "    df2['t_pdays'] = pd.cut(x = df2['pdays'], bins = [-2, 0, 200, 999], labels = ['NON CONTACTE', 'MOINS DE 200J', 'PLUS DE 200J'])\n",
        "\n",
        "    # Creation de tranches de nombre de contact avant la campagne\n",
        "    df2['previous'] = pd.cut(x = df2['previous'], bins = [0, 1, 2, 3, 99], labels = [1, 2, 3, 4])\n",
        "\n",
        "    # Suppression des colonnes dummies\"ées\"\n",
        "    drop_cols=['age','balance','duration','campaign','pdays','previous']\n",
        "    df2 = df2.drop(drop_cols, axis=1)\n",
        "\n",
        "    # Création de dummies\n",
        "    var=['marital','education','poutcome','contact','t_age','t_balance','t_duration','t_campaign','t_pdays','month']\n",
        "    df2= df2.join(pd.get_dummies(df2[var], prefix=var))\n",
        "    df2 = df2.drop(df2[var], axis=1)\n",
        "\n",
        "    # Transformation en numérique\n",
        "    le = LabelEncoder()\n",
        "    df2['job2']= le.fit_transform(df2['job'])\n",
        "    df2 = df2.drop(['job'], axis=1)\n",
        "\n",
        "    # Remplace yes/no par 1/0\n",
        "    var = [\"default\", \"housing\",\"loan\",\"deposit\",\"contact_last_campaign\"]\n",
        "    df2[var] = df2[var].replace(('yes', 'no'), (1, 0))\n",
        "    '''\n",
        "  st.code(code, language='python')\n",
        "\n",
        "\n",
        "# ---------- Arbre de correlations après preprocessing -----------\n",
        "\n",
        "  st.header(\"Arbre de correlations après preprocessing :\")\n",
        "\n",
        "  fig = plt.figure(figsize=(20,15))\n",
        "  plt.title(label=\"Correlation des features avec la variable cible deposit\")\n",
        "  df2.corr()['deposit'].sort_values().drop('deposit').plot(kind='barh', cmap='RdBu_r')\n",
        "  st.pyplot(fig)\n",
        "\n",
        "\n",
        "# ---------- Les enseignements -----------\n",
        "\n",
        "  st.header(\"Les enseignements :\")\n",
        "\n",
        "  st.write(\"On voit clairement que la feature [duration] impacte positivement la campagne dès lors que la valeur est élevée (temps de contact).\")\n",
        "  st.write(\"Egalement, les clients ayant répondu favorablement à la campagne précédente [poutcome] semblent être les plus susceptibles de renouveler leur action.\")\n",
        "  st.write(\"Les mois de mars et octobre [month] semblent être les meilleurs mois pour optimiser les leads.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTfeuTgzz8qJ"
      },
      "source": [
        "### Page 3 - Challenge de modèles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6SZP6qQ0BZ0"
      },
      "outputs": [],
      "source": [
        "%%writefile streamlit_app.py \n",
        "\n",
        "# ______________________________________________________________________________________________________\n",
        "# 4/ Challenge de modèles\n",
        "# ______________________________________________________________________________________________________\n",
        "\n",
        "\n",
        "if page==pages[3]: \n",
        "\n",
        "  st.title(\"Modèles prédictifs\")\n",
        "     \n",
        "\n",
        "# ---------- Initialisation des biblothèques utilisées -----------\n",
        "\n",
        "  from sklearn.metrics import accuracy_score, plot_confusion_matrix, roc_curve, roc_auc_score, auc, precision_score, recall_score, classification_report\n",
        "  from sklearn import linear_model, neighbors, svm, tree, ensemble\n",
        "  from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  df3=df2.copy()\n",
        "\n",
        "\n",
        "# ---------- Split jeu entrainement et jeu de test -----------\n",
        "\n",
        "  # Isoler les features de la target\n",
        "  target = df3['deposit']\n",
        "  feats = df3.drop(['deposit'], axis=1)\n",
        "\n",
        "  # Séparation des données en jeu d'entraînement et de test\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  X_train, X_test, y_train, y_test = train_test_split(feats, target, test_size=0.25)\n",
        "\n",
        "  # Normaliser les données - MinMaxScaler\n",
        "  scaler = MinMaxScaler()\n",
        "  X_train = scaler.fit_transform(X_train)\n",
        "  X_test = scaler.transform(X_test)\n",
        "\n",
        "  # Sauvegarde des résulats de chacun des modèles\n",
        "  models=[]\n",
        "  scores =[]\n",
        "  precision=[]\n",
        "  rappel=[]\n",
        "  roc=[]\n",
        "\n",
        "# ---------- Les 3 modèles -----------\n",
        "\n",
        "  col1, col2, col3, col4 = st.columns(4)\n",
        "\n",
        "# Régression logistique -----------------------------------------------------------------------\n",
        "\n",
        "  with col1:\n",
        "    expander = st.expander(\"Modèle RLC\")\n",
        "    rlc = linear_model.LogisticRegression(C=10)\n",
        "    rlc.fit(X_train, y_train)\n",
        "        \n",
        "    expander.metric(\"Score train\", \"{:.2%}\".format(rlc.score(X_train, y_train)))\n",
        "    expander.metric(\"Score test\", \"{:.2%}\".format(rlc.score(X_test, y_test)))\n",
        "    expander.metric(\"Precision Score\", \"{:.2%}\".format(precision_score(y_test, rlc.predict(X_test))))\n",
        "\n",
        "    y_pred = rlc.predict(X_test)\n",
        "    expander.write(\"Matrice de confusion :\")\n",
        "    expander.write(pd.crosstab(y_test, y_pred, rownames=['Classe réelle'], colnames=['Classe prédite']))\n",
        "\n",
        "    # Sauvegarde des résultats\n",
        "    models.append(\"Regression logistique\")\n",
        "    scores.append(rlc.score(X_test, y_test))\n",
        "    precision.append(precision_score(y_test, rlc.predict(X_test)))\n",
        "    rappel.append(recall_score(y_test, rlc.predict(X_test)))\n",
        "    roc.append(roc_auc_score(y_test, rlc.predict(X_test)))\n",
        "    probs_rlc = rlc.predict_proba(X_test)\n",
        "\n",
        "# K plus proche voisins -----------------------------------------------------------------------\n",
        "\n",
        "  with col2:\n",
        "    expander = st.expander(\"Modèle KNN\")\n",
        "\n",
        "    knn = neighbors.KNeighborsClassifier(n_neighbors=39)\n",
        "    knn.fit(X_train, y_train)\n",
        "      \n",
        "    expander.metric(\"Score train\", \"{:.2%}\".format(knn.score(X_train, y_train)))\n",
        "    expander.metric(\"Score test\", \"{:.2%}\".format(knn.score(X_test, y_test)))\n",
        "    expander.metric(\"Precision Score\", \"{:.2%}\".format(precision_score(y_test, knn.predict(X_test))))\n",
        "\n",
        "    y_pred = knn.predict(X_test)\n",
        "    expander.write(\"Matrice de confusion :\")\n",
        "    expander.write(pd.crosstab(y_test, y_pred, rownames=['Classe réelle'], colnames=['Classe prédite']))\n",
        "\n",
        "    # Sauvegarde des résultats\n",
        "    models.append(\"K plus proches voisins\")\n",
        "    scores.append(knn.score(X_test, y_test))\n",
        "    precision.append(precision_score(y_test, knn.predict(X_test)))\n",
        "    rappel.append(recall_score(y_test, knn.predict(X_test)))\n",
        "    roc.append(roc_auc_score(y_test, knn.predict(X_test)))\n",
        "    probs_knn = knn.predict_proba(X_test)\n",
        "\n",
        "# Arbre de décision -----------------------------------------------------------------------\n",
        "\n",
        "  with col3:\n",
        "    expander = st.expander(\"Modèle DTC\")\n",
        "\n",
        "    dtc = tree.DecisionTreeClassifier(max_depth=9)\n",
        "    dtc.fit(X_train, y_train)  \n",
        "        \n",
        "    expander.metric(\"Score train\", \"{:.2%}\".format(dtc.score(X_train, y_train)))\n",
        "    expander.metric(\"Score test\", \"{:.2%}\".format(dtc.score(X_test, y_test)))\n",
        "    expander.metric(\"Precision Score\", \"{:.2%}\".format(precision_score(y_test, dtc.predict(X_test))))\n",
        "\n",
        "    y_pred = dtc.predict(X_test)\n",
        "    expander.write(\"Matrice de confusion :\")\n",
        "    expander.write(pd.crosstab(y_test, y_pred, rownames=['Classe réelle'], colnames=['Classe prédite']))\n",
        "\n",
        "    # Sauvegarde des résultats\n",
        "    models.append(\"Decision Tree\")\n",
        "    scores.append(dtc.score(X_test, y_test))\n",
        "    precision.append(precision_score(y_test, dtc.predict(X_test)))\n",
        "    rappel.append(recall_score(y_test, dtc.predict(X_test)))\n",
        "    roc.append(roc_auc_score(y_test, dtc.predict(X_test)))\n",
        "    probs_dtc = dtc.predict_proba(X_test)\n",
        "\n",
        "# Random Forest -----------------------------------------------------------------------\n",
        "\n",
        "  with col4:\n",
        "    expander = st.expander(\"Modèle RFC\")\n",
        "\n",
        "    rfc = ensemble.RandomForestClassifier(n_jobs=1) \n",
        "    rfc.fit(X_train, y_train)\n",
        "    \n",
        "    expander.metric(\"Score train\", \"{:.2%}\".format(rfc.score(X_train, y_train)))\n",
        "    expander.metric(\"Score test\", \"{:.2%}\".format(rfc.score(X_test, y_test)))\n",
        "    expander.metric(\"Precision Score\", \"{:.2%}\".format(precision_score(y_test, rfc.predict(X_test))))\n",
        "\n",
        "    y_pred = rfc.predict(X_test)\n",
        "    expander.write(\"Matrice de confusion :\")\n",
        "    expander.write(pd.crosstab(y_test, y_pred, rownames=['Classe réelle'], colnames=['Classe prédite']))\n",
        "\n",
        "    # Sauvegarde des résultats\n",
        "    models.append(\"Random Forest\")\n",
        "    scores.append(rfc.score(X_test, y_test))\n",
        "    precision.append(precision_score(y_test, rfc.predict(X_test)))\n",
        "    rappel.append(recall_score(y_test, rfc.predict(X_test)))\n",
        "    roc.append(roc_auc_score(y_test, rfc.predict(X_test)))\n",
        "    probs_rfc = rfc.predict_proba(X_test)\n",
        "\n",
        "\n",
        "# Comparaison des résultats -----------------------------------------------------------------------\n",
        "\n",
        "  expander = st.expander(\"Comparaison des 4 modèles\")\n",
        "\n",
        "  # Recap des scores\n",
        "  compare = pd.DataFrame(models)\n",
        "  compare.columns = ['model']\n",
        "  compare[\"accuracy\"]=scores\n",
        "  compare[\"precision\"]=precision\n",
        "  compare[\"rappel\"]=rappel\n",
        "  compare[\"roc\"]=roc\n",
        "\n",
        "  #Graphique de comparaison des résultats\n",
        "  fig = plt.figure(figsize=(20,10))\n",
        "\n",
        "#  compare.plot.bar(x = 'model', y=['accuracy', 'precision', 'rappel','roc'],stacked=False, rot=90)\n",
        "\n",
        "  plt.bar(x = 'model', y=['accuracy', 'precision', 'rappel','roc'])\n",
        "\n",
        "  plt.ylim([0.5, 1])\n",
        "  plt.axhline(y=0.80, color='k', linewidth=2, linestyle='--')\n",
        "  plt.title(\"Compare Models\")\n",
        "  expander.pyplot(fig)\n",
        "\n",
        "\n",
        "  # Comparaison avec l'indice des ROC\n",
        "  fig = plt.figure(figsize=(20,10))\n",
        "\n",
        "  # Regression logistique\n",
        "  fpr, tpr, seuils = roc_curve(y_test, probs_rlc[:,1])\n",
        "  roc_auc = auc(fpr, tpr)\n",
        "  plt.plot(fpr, tpr, color='green', lw=2, label='Modèle RLC (auc = %0.2f)' % roc_auc)\n",
        "\n",
        "  # K plus proches voisins\n",
        "  fpr, tpr, seuils = roc_curve(y_test, probs_knn[:,1])\n",
        "  roc_auc = auc(fpr, tpr)\n",
        "  plt.plot(fpr, tpr, color='blue', lw=2, label='Modèle KNN (auc = %0.2f)' % roc_auc)\n",
        "\n",
        "  # Decision Tree\n",
        "  fpr, tpr, seuils = roc_curve(y_test, probs_dtc[:,1])\n",
        "  roc_auc = auc(fpr, tpr)\n",
        "  plt.plot(fpr, tpr, color='orange', lw=2, label='Modèle DTC (auc = %0.2f)' % roc_auc)\n",
        "\n",
        "  # Random Forest\n",
        "  fpr, tpr, seuils = roc_curve(y_test, probs_rfc[:,1])\n",
        "  roc_auc = auc(fpr, tpr)\n",
        "  plt.plot(fpr, tpr, color='red', lw=2, label='Modèle RFC (auc = %0.2f)' % roc_auc)\n",
        "\n",
        "  plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--', label='Aléatoire (auc = 0.5)')\n",
        "  plt.xlim([0.0, 1.0])\n",
        "  plt.ylim([0.0, 1.05])\n",
        "  plt.xlabel('Taux faux positifs')\n",
        "  plt.ylabel('Taux vrais positifs')\n",
        "  plt.title('Courbe ROC pour modèle Random Forest')\n",
        "  plt.legend(loc=\"lower right\")\n",
        "  expander.pyplot(fig)\n",
        "\n",
        "  expander = st.expander(\"Choix du modèle\")\n",
        "  expander.write(\"Le modèle Random Forest semble le plus équilibré. Il permet de maximiser les positifs.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmQcWD950GOr"
      },
      "source": [
        "### Page 4 - Pour aller plus loin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_pE_H730Kdf"
      },
      "outputs": [],
      "source": [
        "%%writefile streamlit_app.py \n",
        "\n",
        "# ______________________________________________________________________________________________________\n",
        "# 5/ BONUS\n",
        "# ______________________________________________________________________________________________________\n",
        "\n",
        "\n",
        "if page==pages[4]: \n",
        "\n",
        "  st.title(\"Estimation du nombre de leads sur la future campagne\")\n",
        "\n",
        "  from datetime import datetime\n",
        "  #d = st.date_input(\"A quelle date souhaitez-vous lancer la campagne\",datetime.date(2022, 7, 1))\n",
        "  d = st.date_input(\"When's your birthday\", datetime.date(2020, 8, 11))\n",
        "  t = st.time_input(\"A combien estimez-vous le temps d'un appel client\", datetime.time(8, 45))\n",
        "\n",
        "  start_time = st.slider(\"When do you start?\",value=d,format=\"MM/DD/YY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEvMIf1k0Z4F"
      },
      "source": [
        "# Exécution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPfbpdGoxJ-A"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['NUMEXPR_MAX_THREADS'] = '16'\n",
        "os.environ['NUMEXPR_NUM_THREADS'] = '8'\n",
        "import numexpr as ne\n",
        "\n",
        "# run streamlit\n",
        "!streamlit run streamlit_app.py & public_url"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run streamlit_app.py"
      ],
      "metadata": {
        "id": "2HYdZAEaO3Iz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copie de Projet JAD'Up.ipynb",
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}