{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amelievert/JAD-Up/blob/main/Projet_JAD'Up.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsfm0KCuyPWW"
      },
      "source": [
        "# Projet d'application Streamlit"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.7.9 . So i Recommend to uninstall all the previous version and install python 3.7 and try running the command: \"pip install streamlit\" or \"pip install --upgrade streamlit\"\n",
        "\n"
      ],
      "metadata": {
        "id": "3q7p_a0j8Ond"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxZmRS0AyV5y"
      },
      "source": [
        "### Installation Streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZHGxkgYhcEZ"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbRTmXNhy8ae"
      },
      "source": [
        "### Configuration du site"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "decbyG24zBPo"
      },
      "outputs": [],
      "source": [
        "%%writefile streamlit_app.py \n",
        "\n",
        "# ______________________________________________________________________________________________________\n",
        "# Import des biblioth√®ques\n",
        "# ______________________________________________________________________________________________________\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier \n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "\n",
        "# ______________________________________________________________________________________________________\n",
        "# Configuration du site\n",
        "# ______________________________________________________________________________________________________\n",
        "\n",
        "st.set_page_config(page_title=\"JAD'Up\",  layout='wide', page_icon='/content/Agence de Marketing.ico')\n",
        "\n",
        "st.sidebar.title(\"Sommaire\")\n",
        "st.sidebar.image('/content/Agence de Marketing.ico')\n",
        "\n",
        "pages = [\"Introduction au jeu de donn√©es\",\n",
        "         \"Analyse\",\n",
        "         \"Preprocessing\",\n",
        "         \"Challenge de mod√®les\",\n",
        "         \"Pour aller plus loin\"]\n",
        "\n",
        "page = st.sidebar.radio(\"Aller vers\", pages) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r13z8KkwzUbW"
      },
      "source": [
        "### Pr√©paration des jeux de donn√©es"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpFAZyPSzKwx"
      },
      "outputs": [],
      "source": [
        "%%writefile streamlit_app.py \n",
        "\n",
        "# ______________________________________________________________________________________________________\n",
        "# Import du jeu de donn√©es\n",
        "# ______________________________________________________________________________________________________\n",
        "\n",
        "df = pd.read_csv('/content/bank.csv', sep = ',')\n",
        "\n",
        "\n",
        "# ______________________________________________________________________________________________________\n",
        "# Pr√©paration des jeux de donn√©es √† utiliser\n",
        "# ______________________________________________________________________________________________________\n",
        "\n",
        "df2 = df.copy()\n",
        "\n",
        "# Creation de tranches d'√¢ges\n",
        "df2['t_age'] = pd.cut(x = df2['age'], bins = [17, 30, 40, 50, 65, 96], labels = ['18-30', '30-40','40-50', '50-65','65-95'])\n",
        "\n",
        "# Creation de tranches de solde compte bancaire = balance\n",
        "df2['t_balance'] = pd.qcut(x=df2[\"balance\"], q=4, labels=[1,2,3,4])\n",
        "\n",
        "# Creation de tranches de dur√©e de contact = duration\n",
        "df2['t_duration'] = pd.qcut(df2[\"duration\"], q=4, labels=[1,2,3,4])\n",
        "\n",
        "# Creation de tranches de dur√©e de contact = duration\n",
        "df2['t_duration'] = pd.qcut(df2[\"duration\"], q=4, labels=[1,2,3,4])\n",
        "\n",
        "# Creation de tranches de nombre de contact = campaign > Corrige le probl√®me de valeurs abb√©rantes et limite √† 4 contacts\n",
        "df2['t_campaign'] = pd.cut(x = df2['campaign'], bins = [0, 1, 2, 3, 99], labels = [1, 2, 3, 4])\n",
        "\n",
        "# Cr√©ation d'une cat√©gorie pour contact campagne pr√©c√©dente oui/non\n",
        "df2['contact_last_campaign'] = np.where(df2['pdays']>=0, 'yes', 'no')\n",
        "\n",
        "# Cr√©ation de tranches en fonction du d√©lai √©coul√©\n",
        "df2['t_pdays'] = pd.cut(x = df2['pdays'], bins = [-2, 0, 200, 999], labels = ['NON CONTACTE', 'MOINS DE 200J', 'PLUS DE 200J'])\n",
        "\n",
        "# Creation de tranches de nombre de contact avant la campagne\n",
        "df2['previous'] = pd.cut(x = df2['previous'], bins = [0, 1, 2, 3, 99], labels = [1, 2, 3, 4])\n",
        "\n",
        "# Suppression des colonnes dummies\"√©es\"\n",
        "drop_cols=['age','balance','duration','campaign','pdays','previous']\n",
        "df2 = df2.drop(drop_cols, axis=1)\n",
        "\n",
        "# Cr√©ation de dummies\n",
        "var=['marital','education','poutcome','contact','t_age','t_balance','t_duration','t_campaign','t_pdays','month']\n",
        "df2= df2.join(pd.get_dummies(df2[var], prefix=var))\n",
        "df2 = df2.drop(df2[var], axis=1)\n",
        "\n",
        "# Transformation en num√©rique\n",
        "le = LabelEncoder()\n",
        "df2['job2']= le.fit_transform(df2['job'])\n",
        "df2 = df2.drop(['job'], axis=1)\n",
        "\n",
        "# Remplace yes/no par 1/0\n",
        "var = [\"default\", \"housing\",\"loan\",\"deposit\",\"contact_last_campaign\"]\n",
        "df2[var] = df2[var].replace(('yes', 'no'), (1, 0))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cy6gdue80NEP"
      },
      "source": [
        "# Construction du site"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGTRoPZHzcDj"
      },
      "source": [
        "### Page 0 - Introduction au jeu de donn√©es"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4qWjCJXzkMz"
      },
      "outputs": [],
      "source": [
        "%%writefile streamlit_app.py \n",
        "\n",
        "# ______________________________________________________________________________________________________\n",
        "# 1/ Introduction au jeu de donn√©es\n",
        "# ______________________________________________________________________________________________________\n",
        "\n",
        "if page==pages[0]: \n",
        "\n",
        "  st.title(\"Description du jeu de donn√©es\")\n",
        "\n",
        "  st.write(\"Ce jeu de donn√©es est compos√© de donn√©es personnelles sur des clients d‚Äôune banque qui ont √©t√© ‚Äút√©l√©market√©s‚Äù pour souscrire √† un produit que l‚Äôon appelle un 'd√©p√¥t √† terme'.\")\n",
        "  st.write(\"Lorsqu‚Äôun client souscrit √† ce produit, il place une quantit√© d‚Äôargent dans un compte sp√©cifique et ne pourra pas toucher ces fonds avant l‚Äôexpiration du terme.\")\n",
        "  st.write(\"En √©change, le client re√ßoit des int√©r√™ts de la part de la banque √† la fin du terme.\")\n",
        "  st.write(\"Le jeu de donn√©es est t√©l√©chargeable au lien suivant: \")\n",
        "  st.write(\"https://www.kaggle.com/janiobachmann/bank-marketing-dataset\")\n",
        "\n",
        "\n",
        "# ---------- Les chiffres cl√©s -----------\n",
        "\n",
        "  st.header(\"Les chiffres cl√©s :\")\n",
        "  col1, col2, col3, col4, col5 = st.columns(5)\n",
        "  col1.write('')\n",
        "  col2.metric(\"Nombre de clients\", \"11 162\")\n",
        "  col3.metric(\"Nombre de features\", \"17\")\n",
        "  col4.metric(\"Proportion des cibles\", \"47%\")\n",
        "  col5.write('')\n",
        "\n",
        "# ---------- les variables  -----------\n",
        "\n",
        "  st.header(\"Description des variables :\")\n",
        "\n",
        "  var = pd.DataFrame({\"Nom des variables\": [\"age\",\"job\",\"marital\",\"education\",\"default\",\"balance\",\"housing\",\"loan\",\"contact\",\"day\",\"month\",\"duration\",\"campaign\",\"pdays\",\"previous\",\"poutcome\",\"deposit\"],\n",
        "    \"Description\": [\"Age du client\",\"Profession\",\"Statut marital\",\"Niveau d'√©tudes\",\"D√©faut de paiement\",\"Solde du compte\",\"Pr√™t immo\",\"Pr√™t perso\",\n",
        "    \"Type de contact\",\"Dernier jour de contact\",\"Dernier mois de  contact\",\"Dur√©e du contact (secondes)\",\"Nombre de contacts\",\"Nb jours √©coul√©s depuis le dernier contact\",\"Nb de contacts\",\n",
        "    \"R√©sultat de la campagne pr√©c√©dente\",\"R√©sultat de la campagne en cours\"]\n",
        "    })\n",
        "\n",
        "  st.write(var)\n",
        "\n",
        "# ---------- Aper√ßu -----------\n",
        "\n",
        "  st.header(\"Aper√ßu du jeu de donn√©es :\")\n",
        "  st.write(df)\n",
        "\n",
        "# ---------- Ce qu'il faut comprendre -----------\n",
        "\n",
        "  st.header(\"Ce qu'il faut retenir :\")\n",
        "  st.write(\"On remarque que certaines variables sont la r√©sultante de la campagne en cours : \")\n",
        "  st.write(\"* contact\")\n",
        "  st.write(\"* day\")\n",
        "  st.write(\"* month\")\n",
        "  st.write(\"* duration\")\n",
        "  st.write(\"* campaign\")\n",
        "  st.write(\"La variable [deposit] est notre variable cible.\")\n",
        "  st.write(\"47% des clients ont r√©pondu favorablement √† la campagne (deposit=yes)\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA5wCQBgzue0"
      },
      "source": [
        "### Page 1 - Analyse du jeu de donn√©es"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQ1lXYj-zw5Q"
      },
      "outputs": [],
      "source": [
        "%%writefile streamlit_app.py \n",
        "\n",
        "# ______________________________________________________________________________________________________\n",
        "# 2/ Analyse du jeu de donn√©es\n",
        "# ______________________________________________________________________________________________________\n",
        "\n",
        "if page==pages[1]: \n",
        "\n",
        "  st.title(\"Analyse du jeu de donn√©es\")\n",
        "\n",
        "# ---------- Fonction de description -----------\n",
        "\n",
        "  def describe_df(df):\n",
        "      \"\"\"\n",
        "      Fonction am√©lior√©e de description des colonnes, elle permet d'identifier :\n",
        "      le type de la colonne , le nb de valeur vide (nan), le nb de valeurs uniques, le pourcentage de r√©partition des valeurs\n",
        "      INPUT : le dataframe\n",
        "      OUTPUT : tableau d'analyse\n",
        "      \"\"\"\n",
        "      res = pd.DataFrame(index=[\"Name\",\"Type\", \"Nan\", \"Unique\",\"Min\",\"Max\",\"Values\",\"Pourcentage\"])\n",
        "      for col in df.columns:\n",
        "          df_col = df[col]\n",
        "          res[col] = [\n",
        "              df_col.name,\n",
        "              df_col.dtype,\n",
        "              df_col.isnull().sum(),\n",
        "              len(df_col.unique()),\n",
        "              df_col.min(),\n",
        "              df_col.max(),\n",
        "              df_col.unique(),\n",
        "              (df_col.value_counts(ascending=False, normalize=True) * 100)\n",
        "                  .apply(int)\n",
        "                  .to_json(),\n",
        "          ]\n",
        "      return res.T\n",
        "\n",
        "# ---------- Affichage de la description d√©taill√©e -----------\n",
        "\n",
        "  description = st.expander(\"Afficher la description des colonnes\")\n",
        "  description.dataframe(describe_df(df).astype(str))\n",
        "\n",
        "\n",
        "# ---------- Les correlations -----------\n",
        "\n",
        "  col1, col2 = st.columns(2)\n",
        "\n",
        "# Matrice de correlation\n",
        "\n",
        "  le = LabelEncoder()\n",
        "  df2=df.copy()\n",
        "  for col in df2.columns:\n",
        "    df2[col]= le.fit_transform(df2[col])\n",
        "  \n",
        "  col1.subheader(\"Matrice de corr√©lation\")\n",
        "\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  sns.heatmap(df2.corr(), annot=True, cmap='RdBu_r', center=0)\n",
        "  col1.pyplot(fig)\n",
        "\n",
        "\n",
        "# Corr√©lations directes\n",
        "\n",
        "  tab1, tab2 = col2.tabs([\"üìà Chart\", \"üóÉ Coefficients\"])\n",
        "\n",
        "  tab1.subheader(\"Graphiques des corr√©lations directes\")\n",
        "  \n",
        "  corr=pd.DataFrame(df2.corr()[\"deposit\"])\n",
        "  corr=corr.sort_values(\"deposit\",ascending=False, key=abs)\n",
        "\n",
        "  fig = plt.figure(figsize=(10,7))\n",
        "  fig = px.bar(corr,\n",
        "                 x=\"Deposit\",\n",
        "                 y=corr.index,\n",
        "                 template = 'seaborn')\n",
        "  tab1.plotly_chart(fig, use_container_width=True) \n",
        "\n",
        "\n",
        "  tab2.subheader(\"Coefficients\")\n",
        "\n",
        "  coef=df2.corr()[\"deposit\"]\n",
        "  tab2.write(coef)\n",
        "\n",
        "# ---------- Les observations -----------\n",
        "\n",
        "  st.subheader(\"Observations :\")\n",
        "\n",
        "  st.write(\"Dans l'ordre, les variables les plus corr√©l√©es (valeur absolue) avec la target 'd√©posit' sont :\")\n",
        "  st.write(\"* duration*** = Dur√©e du contact (en secondes)\")\n",
        "  st.write(\"* contact*** = Type de contact\")\n",
        "  st.write(\"* housing = Pr√™t immo\")\n",
        "  st.write(\"* previous = Nb contacts au cours de la campagne pr√©c√©dente\")\n",
        "  st.write(\"* pdays = Nb jours √©coul√©s depuis le dernier contact de la campagne pr√©c√©dente\")\n",
        "  st.write(\"* balance = Solde compte bancaire\")\n",
        "  st.write(\"*** : attention , deux variables correspondent √† des donn√©es non connues √† priori (avant lancement de la campagne\")\n",
        "\n",
        "\n",
        "# ---------- Les distributions par type de variables -----------\n",
        "\n",
        "  st.subheader(\"Les distributions :\")\n",
        "  col3, col4 = st.columns(2)\n",
        "  df2 = df.copy()\n",
        "  numerics = df2.select_dtypes(include=['int16', 'int32', 'int64', 'float16', 'float32', 'float64']).columns\n",
        "  categoricals= df2.select_dtypes(include=['object','category']).columns\n",
        "\n",
        "\n",
        "# variables num√©riques\n",
        "\n",
        "  col3.subheader(\"Variables num√©riques\")\n",
        "  tab3, tab4 = col3.tabs([\"üóÉ Describe\", \"üìà Chart\"])\n",
        "\n",
        "  describe= df2[numerics].describe().transpose()\n",
        "  tab3.write(describe)\n",
        "\n",
        "  option = tab4.selectbox(\"Choix une variable num√©rique :\",numerics)\n",
        "  hist = px.histogram(df2,x=option,color=\"deposit\",barmode=\"group\")\n",
        "  tab4.plotly_chart(hist)\n",
        "\n",
        "  if option==\"age\":\n",
        "    tab4.write(\"Les √¢ges extr√™mes semblent avoir une plus forte adh√©rence avec la campagne.\")\n",
        "  elif option==\"balance\":\n",
        "    tab4.write(\"RAS\")\n",
        "  elif option==\"day\":\n",
        "    tab4.write(\"RAS\")\n",
        "  elif option==\"duration\":\n",
        "    tab4.write(\"On remarque que plus la dur√©e de contact augmente et plus les clients semblent souscrire √† la campagne.\")\n",
        "  elif option==\"campaign\":\n",
        "    tab4.write(\"RAS\")\n",
        "  elif option==\"pdays\":\n",
        "    tab4.write(\"RAS\")\n",
        "  elif option==\"previous\":\n",
        "    tab4.write(\"RAS\")\n",
        "\n",
        "  col3.header(\"Observations\")\n",
        "  col3.write(\"On remarque que 8 324 clients n'ont pas √©t√© contact√©s lors de la campagne pr√©c√©dente.\")\n",
        "  col3.write(\"Lorsque PREVIOUS = 0 alors PDAYS = -1\")\n",
        "\n",
        "# variables cat√©gorielles\n",
        "\n",
        "  col4.subheader(\"Variables cat√©gorielles\")\n",
        "  tab5, tab6 = col3.tabs([\"üóÉ Describe\", \"üìà Chart\"])\n",
        "\n",
        "  describe= df2[categoricals].describe().transpose()\n",
        "  tab5.write(describe)\n",
        "\n",
        "  option = tab6.selectbox(\"Choix une variable :\", categoricals)\n",
        "  hist = px.histogram(df2,x=option,color=\"deposit\")\n",
        "  tab6.plotly_chart(hist)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJf1c-eGz0yZ"
      },
      "source": [
        "### Page 2 - Pr√©processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCc_xN5Dz2-S"
      },
      "outputs": [],
      "source": [
        "%%writefile streamlit_app.py \n",
        "\n",
        "# ______________________________________________________________________________________________________\n",
        "# 3/ Pr√©processing\n",
        "# ______________________________________________________________________________________________________\n",
        "\n",
        "\n",
        "if page==pages[2]: \n",
        "\n",
        "  st.title(\"Pr√©processing - Mod√®les pr√©dictifs\")\n",
        "\n",
        "# ---------- Remise √† situation d'origine -----------\n",
        "\n",
        "  # R√©import du fichier\n",
        "  df2 = df.copy()\n",
        "\n",
        "# ---------- Temps de preprocessing -----------\n",
        "\n",
        "  st.write(\"Attendre le traitement des variables ...\")\n",
        "\n",
        "  import time\n",
        "  my_bar = st.progress(0)\n",
        "  for percent_complete in range(100):\n",
        "      time.sleep(0.1)\n",
        "      my_bar.progress(percent_complete + 1)\n",
        "\n",
        "\n",
        "# ---------- Le pr√©processing, √ßa sert √† quoi -----------\n",
        "\n",
        "  expander1 = st.expander(\"Le pr√©processing, √ßa sert √† quoi ?\")\n",
        "  expander1.dataframe(describe_df(df).astype(str))\n",
        "\n",
        "  expander1.write(\"Le pr√©processing est une de composante essentielle de la data science.\")\n",
        "  expander1.write(\"Cette √©tape d√©crit toutes les transformations effectu√©es sur le jeu de donn√©es initial et indispensables √† la cr√©ation du mod√®le d'apprentissage fiable et robuste.\")\n",
        "  expander1.write(\"Les algorithmes d'apprentissage automatique fonctionnent mieux lorsque les donn√©es sont pr√©sent√©es dans un format qui met en √©vidence les aspects pertinents requis pour r√©soudre un probl√®me.\")\n",
        "  expander1.write(\"Les fonctions de pr√©processing consistent √† : \")\n",
        "  expander1.write(\"* la transformation des donn√©es,\")\n",
        "  expander1.write(\"* la r√©duction des donn√©es,\")\n",
        "  expander1.write(\"* la s√©lection des variables\")\n",
        "  expander1.write(\"* et √† la mise √† l'√©chelle\")\n",
        "  expander1.write(\"pour restructurer les donn√©es brutes sous une forme adapt√©e √† des types particuliers d'algorithmes.\")\n",
        "\n",
        "  from PIL import Image\n",
        "  image = Image.open('preprocessing.JPG')\n",
        "  expander1.image(image, caption='Les √©tapes de pr√©processing')\n",
        "\n",
        "# ---------- Les √©tapes de pr√©processing -----------\n",
        "\n",
        "  st.header(\"Les √©tapes de pr√©processing appliqu√©es :\")\n",
        "\n",
        "  code = ''' \n",
        "    # Creation de tranches d'√¢ges\n",
        "    df2['t_age'] = pd.cut(x = df2['age'], bins = [17, 30, 40, 50, 65, 96], labels = ['18-30', '30-40','40-50', '50-65','65-95'])\n",
        "\n",
        "    # Creation de tranches de solde compte bancaire = balance\n",
        "    df2['t_balance'] = pd.qcut(x=df2[\"balance\"], q=4, labels=[1,2,3,4])\n",
        "\n",
        "    # Creation de tranches de dur√©e de contact = duration\n",
        "    df2['t_duration'] = pd.qcut(df2[\"duration\"], q=4, labels=[1,2,3,4])\n",
        "\n",
        "    # Creation de tranches de dur√©e de contact = duration\n",
        "    df2['t_duration'] = pd.qcut(df2[\"duration\"], q=4, labels=[1,2,3,4])\n",
        "\n",
        "    # Creation de tranches de nombre de contact = campaign > Corrige le probl√®me de valeurs abb√©rantes et limite √† 4 contacts\n",
        "    df2['t_campaign'] = pd.cut(x = df2['campaign'], bins = [0, 1, 2, 3, 99], labels = [1, 2, 3, 4])\n",
        "\n",
        "    # Cr√©ation d'une cat√©gorie pour contact campagne pr√©c√©dente oui/non\n",
        "    df2['contact_last_campaign'] = np.where(df2['pdays']>=0, 'yes', 'no')\n",
        "\n",
        "    # Cr√©ation de tranches en fonction du d√©lai √©coul√©\n",
        "    df2['t_pdays'] = pd.cut(x = df2['pdays'], bins = [-2, 0, 200, 999], labels = ['NON CONTACTE', 'MOINS DE 200J', 'PLUS DE 200J'])\n",
        "\n",
        "    # Creation de tranches de nombre de contact avant la campagne\n",
        "    df2['previous'] = pd.cut(x = df2['previous'], bins = [0, 1, 2, 3, 99], labels = [1, 2, 3, 4])\n",
        "\n",
        "    # Suppression des colonnes dummies\"√©es\"\n",
        "    drop_cols=['age','balance','duration','campaign','pdays','previous']\n",
        "    df2 = df2.drop(drop_cols, axis=1)\n",
        "\n",
        "    # Cr√©ation de dummies\n",
        "    var=['marital','education','poutcome','contact','t_age','t_balance','t_duration','t_campaign','t_pdays','month']\n",
        "    df2= df2.join(pd.get_dummies(df2[var], prefix=var))\n",
        "    df2 = df2.drop(df2[var], axis=1)\n",
        "\n",
        "    # Transformation en num√©rique\n",
        "    le = LabelEncoder()\n",
        "    df2['job2']= le.fit_transform(df2['job'])\n",
        "    df2 = df2.drop(['job'], axis=1)\n",
        "\n",
        "    # Remplace yes/no par 1/0\n",
        "    var = [\"default\", \"housing\",\"loan\",\"deposit\",\"contact_last_campaign\"]\n",
        "    df2[var] = df2[var].replace(('yes', 'no'), (1, 0))\n",
        "    '''\n",
        "  st.code(code, language='python')\n",
        "\n",
        "\n",
        "# ---------- Arbre de correlations apr√®s preprocessing -----------\n",
        "\n",
        "  st.header(\"Arbre de correlations apr√®s preprocessing :\")\n",
        "\n",
        "  fig = plt.figure(figsize=(20,15))\n",
        "  plt.title(label=\"Correlation des features avec la variable cible deposit\")\n",
        "  df2.corr()['deposit'].sort_values().drop('deposit').plot(kind='barh', cmap='RdBu_r')\n",
        "  st.pyplot(fig)\n",
        "\n",
        "\n",
        "# ---------- Les enseignements -----------\n",
        "\n",
        "  st.header(\"Les enseignements :\")\n",
        "\n",
        "  st.write(\"On voit clairement que la feature [duration] impacte positivement la campagne d√®s lors que la valeur est √©lev√©e (temps de contact).\")\n",
        "  st.write(\"Egalement, les clients ayant r√©pondu favorablement √† la campagne pr√©c√©dente [poutcome] semblent √™tre les plus susceptibles de renouveler leur action.\")\n",
        "  st.write(\"Les mois de mars et octobre [month] semblent √™tre les meilleurs mois pour optimiser les leads.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTfeuTgzz8qJ"
      },
      "source": [
        "### Page 3 - Challenge de mod√®les"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6SZP6qQ0BZ0"
      },
      "outputs": [],
      "source": [
        "%%writefile streamlit_app.py \n",
        "\n",
        "# ______________________________________________________________________________________________________\n",
        "# 4/ Challenge de mod√®les\n",
        "# ______________________________________________________________________________________________________\n",
        "\n",
        "\n",
        "if page==pages[3]: \n",
        "\n",
        "  st.title(\"Mod√®les pr√©dictifs\")\n",
        "     \n",
        "\n",
        "# ---------- Initialisation des bibloth√®ques utilis√©es -----------\n",
        "\n",
        "  from sklearn.metrics import accuracy_score, plot_confusion_matrix, roc_curve, roc_auc_score, auc, precision_score, recall_score, classification_report\n",
        "  from sklearn import linear_model, neighbors, svm, tree, ensemble\n",
        "  from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  df3=df2.copy()\n",
        "\n",
        "\n",
        "# ---------- Split jeu entrainement et jeu de test -----------\n",
        "\n",
        "  # Isoler les features de la target\n",
        "  target = df3['deposit']\n",
        "  feats = df3.drop(['deposit'], axis=1)\n",
        "\n",
        "  # S√©paration des donn√©es en jeu d'entra√Ænement et de test\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  X_train, X_test, y_train, y_test = train_test_split(feats, target, test_size=0.25)\n",
        "\n",
        "  # Normaliser les donn√©es - MinMaxScaler\n",
        "  scaler = MinMaxScaler()\n",
        "  X_train = scaler.fit_transform(X_train)\n",
        "  X_test = scaler.transform(X_test)\n",
        "\n",
        "  # Sauvegarde des r√©sulats de chacun des mod√®les\n",
        "  models=[]\n",
        "  scores =[]\n",
        "  precision=[]\n",
        "  rappel=[]\n",
        "  roc=[]\n",
        "\n",
        "# ---------- Les 3 mod√®les -----------\n",
        "\n",
        "  col1, col2, col3, col4 = st.columns(4)\n",
        "\n",
        "# R√©gression logistique -----------------------------------------------------------------------\n",
        "\n",
        "  with col1:\n",
        "    expander = st.expander(\"Mod√®le RLC\")\n",
        "    rlc = linear_model.LogisticRegression(C=10)\n",
        "    rlc.fit(X_train, y_train)\n",
        "        \n",
        "    expander.metric(\"Score train\", \"{:.2%}\".format(rlc.score(X_train, y_train)))\n",
        "    expander.metric(\"Score test\", \"{:.2%}\".format(rlc.score(X_test, y_test)))\n",
        "    expander.metric(\"Precision Score\", \"{:.2%}\".format(precision_score(y_test, rlc.predict(X_test))))\n",
        "\n",
        "    y_pred = rlc.predict(X_test)\n",
        "    expander.write(\"Matrice de confusion :\")\n",
        "    expander.write(pd.crosstab(y_test, y_pred, rownames=['Classe r√©elle'], colnames=['Classe pr√©dite']))\n",
        "\n",
        "    # Sauvegarde des r√©sultats\n",
        "    models.append(\"Regression logistique\")\n",
        "    scores.append(rlc.score(X_test, y_test))\n",
        "    precision.append(precision_score(y_test, rlc.predict(X_test)))\n",
        "    rappel.append(recall_score(y_test, rlc.predict(X_test)))\n",
        "    roc.append(roc_auc_score(y_test, rlc.predict(X_test)))\n",
        "    probs_rlc = rlc.predict_proba(X_test)\n",
        "\n",
        "# K plus proche voisins -----------------------------------------------------------------------\n",
        "\n",
        "  with col2:\n",
        "    expander = st.expander(\"Mod√®le KNN\")\n",
        "\n",
        "    knn = neighbors.KNeighborsClassifier(n_neighbors=39)\n",
        "    knn.fit(X_train, y_train)\n",
        "      \n",
        "    expander.metric(\"Score train\", \"{:.2%}\".format(knn.score(X_train, y_train)))\n",
        "    expander.metric(\"Score test\", \"{:.2%}\".format(knn.score(X_test, y_test)))\n",
        "    expander.metric(\"Precision Score\", \"{:.2%}\".format(precision_score(y_test, knn.predict(X_test))))\n",
        "\n",
        "    y_pred = knn.predict(X_test)\n",
        "    expander.write(\"Matrice de confusion :\")\n",
        "    expander.write(pd.crosstab(y_test, y_pred, rownames=['Classe r√©elle'], colnames=['Classe pr√©dite']))\n",
        "\n",
        "    # Sauvegarde des r√©sultats\n",
        "    models.append(\"K plus proches voisins\")\n",
        "    scores.append(knn.score(X_test, y_test))\n",
        "    precision.append(precision_score(y_test, knn.predict(X_test)))\n",
        "    rappel.append(recall_score(y_test, knn.predict(X_test)))\n",
        "    roc.append(roc_auc_score(y_test, knn.predict(X_test)))\n",
        "    probs_knn = knn.predict_proba(X_test)\n",
        "\n",
        "# Arbre de d√©cision -----------------------------------------------------------------------\n",
        "\n",
        "  with col3:\n",
        "    expander = st.expander(\"Mod√®le DTC\")\n",
        "\n",
        "    dtc = tree.DecisionTreeClassifier(max_depth=9)\n",
        "    dtc.fit(X_train, y_train)  \n",
        "        \n",
        "    expander.metric(\"Score train\", \"{:.2%}\".format(dtc.score(X_train, y_train)))\n",
        "    expander.metric(\"Score test\", \"{:.2%}\".format(dtc.score(X_test, y_test)))\n",
        "    expander.metric(\"Precision Score\", \"{:.2%}\".format(precision_score(y_test, dtc.predict(X_test))))\n",
        "\n",
        "    y_pred = dtc.predict(X_test)\n",
        "    expander.write(\"Matrice de confusion :\")\n",
        "    expander.write(pd.crosstab(y_test, y_pred, rownames=['Classe r√©elle'], colnames=['Classe pr√©dite']))\n",
        "\n",
        "    # Sauvegarde des r√©sultats\n",
        "    models.append(\"Decision Tree\")\n",
        "    scores.append(dtc.score(X_test, y_test))\n",
        "    precision.append(precision_score(y_test, dtc.predict(X_test)))\n",
        "    rappel.append(recall_score(y_test, dtc.predict(X_test)))\n",
        "    roc.append(roc_auc_score(y_test, dtc.predict(X_test)))\n",
        "    probs_dtc = dtc.predict_proba(X_test)\n",
        "\n",
        "# Random Forest -----------------------------------------------------------------------\n",
        "\n",
        "  with col4:\n",
        "    expander = st.expander(\"Mod√®le RFC\")\n",
        "\n",
        "    rfc = ensemble.RandomForestClassifier(n_jobs=1) \n",
        "    rfc.fit(X_train, y_train)\n",
        "    \n",
        "    expander.metric(\"Score train\", \"{:.2%}\".format(rfc.score(X_train, y_train)))\n",
        "    expander.metric(\"Score test\", \"{:.2%}\".format(rfc.score(X_test, y_test)))\n",
        "    expander.metric(\"Precision Score\", \"{:.2%}\".format(precision_score(y_test, rfc.predict(X_test))))\n",
        "\n",
        "    y_pred = rfc.predict(X_test)\n",
        "    expander.write(\"Matrice de confusion :\")\n",
        "    expander.write(pd.crosstab(y_test, y_pred, rownames=['Classe r√©elle'], colnames=['Classe pr√©dite']))\n",
        "\n",
        "    # Sauvegarde des r√©sultats\n",
        "    models.append(\"Random Forest\")\n",
        "    scores.append(rfc.score(X_test, y_test))\n",
        "    precision.append(precision_score(y_test, rfc.predict(X_test)))\n",
        "    rappel.append(recall_score(y_test, rfc.predict(X_test)))\n",
        "    roc.append(roc_auc_score(y_test, rfc.predict(X_test)))\n",
        "    probs_rfc = rfc.predict_proba(X_test)\n",
        "\n",
        "\n",
        "# Comparaison des r√©sultats -----------------------------------------------------------------------\n",
        "\n",
        "  expander = st.expander(\"Comparaison des 4 mod√®les\")\n",
        "\n",
        "  # Recap des scores\n",
        "  compare = pd.DataFrame(models)\n",
        "  compare.columns = ['model']\n",
        "  compare[\"accuracy\"]=scores\n",
        "  compare[\"precision\"]=precision\n",
        "  compare[\"rappel\"]=rappel\n",
        "  compare[\"roc\"]=roc\n",
        "\n",
        "  #Graphique de comparaison des r√©sultats\n",
        "  fig = plt.figure(figsize=(20,10))\n",
        "\n",
        "#  compare.plot.bar(x = 'model', y=['accuracy', 'precision', 'rappel','roc'],stacked=False, rot=90)\n",
        "\n",
        "  plt.bar(x = 'model', y=['accuracy', 'precision', 'rappel','roc'])\n",
        "\n",
        "  plt.ylim([0.5, 1])\n",
        "  plt.axhline(y=0.80, color='k', linewidth=2, linestyle='--')\n",
        "  plt.title(\"Compare Models\")\n",
        "  expander.pyplot(fig)\n",
        "\n",
        "\n",
        "  # Comparaison avec l'indice des ROC\n",
        "  fig = plt.figure(figsize=(20,10))\n",
        "\n",
        "  # Regression logistique\n",
        "  fpr, tpr, seuils = roc_curve(y_test, probs_rlc[:,1])\n",
        "  roc_auc = auc(fpr, tpr)\n",
        "  plt.plot(fpr, tpr, color='green', lw=2, label='Mod√®le RLC (auc = %0.2f)' % roc_auc)\n",
        "\n",
        "  # K plus proches voisins\n",
        "  fpr, tpr, seuils = roc_curve(y_test, probs_knn[:,1])\n",
        "  roc_auc = auc(fpr, tpr)\n",
        "  plt.plot(fpr, tpr, color='blue', lw=2, label='Mod√®le KNN (auc = %0.2f)' % roc_auc)\n",
        "\n",
        "  # Decision Tree\n",
        "  fpr, tpr, seuils = roc_curve(y_test, probs_dtc[:,1])\n",
        "  roc_auc = auc(fpr, tpr)\n",
        "  plt.plot(fpr, tpr, color='orange', lw=2, label='Mod√®le DTC (auc = %0.2f)' % roc_auc)\n",
        "\n",
        "  # Random Forest\n",
        "  fpr, tpr, seuils = roc_curve(y_test, probs_rfc[:,1])\n",
        "  roc_auc = auc(fpr, tpr)\n",
        "  plt.plot(fpr, tpr, color='red', lw=2, label='Mod√®le RFC (auc = %0.2f)' % roc_auc)\n",
        "\n",
        "  plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--', label='Al√©atoire (auc = 0.5)')\n",
        "  plt.xlim([0.0, 1.0])\n",
        "  plt.ylim([0.0, 1.05])\n",
        "  plt.xlabel('Taux faux positifs')\n",
        "  plt.ylabel('Taux vrais positifs')\n",
        "  plt.title('Courbe ROC pour mod√®le Random Forest')\n",
        "  plt.legend(loc=\"lower right\")\n",
        "  expander.pyplot(fig)\n",
        "\n",
        "  expander = st.expander(\"Choix du mod√®le\")\n",
        "  expander.write(\"Le mod√®le Random Forest semble le plus √©quilibr√©. Il permet de maximiser les positifs.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmQcWD950GOr"
      },
      "source": [
        "### Page 4 - Pour aller plus loin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_pE_H730Kdf"
      },
      "outputs": [],
      "source": [
        "%%writefile streamlit_app.py \n",
        "\n",
        "# ______________________________________________________________________________________________________\n",
        "# 5/ BONUS\n",
        "# ______________________________________________________________________________________________________\n",
        "\n",
        "\n",
        "if page==pages[4]: \n",
        "\n",
        "  st.title(\"Estimation du nombre de leads sur la future campagne\")\n",
        "\n",
        "  from datetime import datetime\n",
        "  #d = st.date_input(\"A quelle date souhaitez-vous lancer la campagne\",datetime.date(2022, 7, 1))\n",
        "  d = st.date_input(\"When's your birthday\", datetime.date(2020, 8, 11))\n",
        "  t = st.time_input(\"A combien estimez-vous le temps d'un appel client\", datetime.time(8, 45))\n",
        "\n",
        "  start_time = st.slider(\"When do you start?\",value=d,format=\"MM/DD/YY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEvMIf1k0Z4F"
      },
      "source": [
        "# Ex√©cution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPfbpdGoxJ-A"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['NUMEXPR_MAX_THREADS'] = '16'\n",
        "os.environ['NUMEXPR_NUM_THREADS'] = '8'\n",
        "import numexpr as ne\n",
        "\n",
        "# run streamlit\n",
        "!streamlit run streamlit_app.py & public_url"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run streamlit_app.py"
      ],
      "metadata": {
        "id": "2HYdZAEaO3Iz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copie de Projet JAD'Up.ipynb",
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}